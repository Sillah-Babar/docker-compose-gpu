{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHRUF0MOV2N2"
   },
   "source": [
    "# **Mount Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76lGF7Qs82aT",
    "outputId": "23ff2274-4771-455d-d111-c321be32863a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile                 Untitled.ipynb     urdu_lipnet.ipynb:Zone.Identifier\r\n",
      "ImageClassification.ipynb  requirements.txt\r\n",
      "\u001b[0m\u001b[01;34mImages\u001b[0m/                    urdu_lipnet.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIYtWuhoV-6b"
   },
   "source": [
    "# **Install Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "o_zRt5UK6qIh",
    "outputId": "49fd4cd2-f229-4c49-8ad1-86a1e25c63cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting keras==2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.12.0\n",
      "    Uninstalling keras-2.12.0:\n",
      "      Successfully uninstalled keras-2.12.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.12.0 requires keras<2.13,>=2.12.0, but you have keras 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed keras-2.10.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting tensorflow==2.10.0\n",
      "  Downloading tensorflow-2.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (0.32.0)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (23.3.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (16.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (1.16.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (1.6.3)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (1.22.4)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (1.14.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (2.2.0)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (3.8.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (1.4.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (67.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (4.5.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (23.0)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (2.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (3.3.0)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (1.53.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.10.0) (0.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.40.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.17.2)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.27.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4.3)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.2.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.8.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (6.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.0.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.2)\n",
      "Installing collected packages: tensorflow-estimator, tensorboard-data-server, protobuf, keras-preprocessing, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.12.0\n",
      "    Uninstalling tensorflow-estimator-2.12.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.7.0\n",
      "    Uninstalling tensorboard-data-server-0.7.0:\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 1.0.0\n",
      "    Uninstalling google-auth-oauthlib-1.0.0:\n",
      "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.12.1\n",
      "    Uninstalling tensorboard-2.12.1:\n",
      "      Successfully uninstalled tensorboard-2.12.1\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.12.0\n",
      "    Uninstalling tensorflow-2.12.0:\n",
      "      Successfully uninstalled tensorflow-2.12.0\n",
      "Successfully installed google-auth-oauthlib-0.4.6 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "google"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting sk-video\n",
      "  Downloading sk_video-1.1.10-py2.py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from sk-video) (1.10.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from sk-video) (1.22.4)\n",
      "Installing collected packages: sk-video\n",
      "Successfully installed sk-video-1.1.10\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.9/dist-packages (from scipy) (1.22.4)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting mediapipe\n",
      "  Downloading mediapipe-0.9.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.6/33.6 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (3.19.6)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from mediapipe) (1.4.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (23.3.3)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (22.2.0)\n",
      "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.9/dist-packages (from mediapipe) (4.7.0.72)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mediapipe) (3.7.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from mediapipe) (1.22.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (1.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (23.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (5.12.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (8.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (4.39.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->mediapipe) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Installing collected packages: mediapipe\n",
      "Successfully installed mediapipe-0.9.2.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting zarr\n",
      "  Downloading zarr-2.14.2-py3-none-any.whl (203 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.3/203.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from zarr) (1.22.4)\n",
      "Collecting numcodecs>=0.10.0\n",
      "  Downloading numcodecs-0.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting asciitree\n",
      "  Downloading asciitree-0.3.3.tar.gz (4.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting fasteners\n",
      "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.9/dist-packages (from numcodecs>=0.10.0->zarr) (0.4)\n",
      "Building wheels for collected packages: asciitree\n",
      "  Building wheel for asciitree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for asciitree: filename=asciitree-0.3.3-py3-none-any.whl size=5050 sha256=9e0302b34973cde378c2810026470f7599f0f37db8ec5370cc011d6805404782\n",
      "  Stored in directory: /root/.cache/pip/wheels/07/00/bc/937e878be0d781a569792a1e0e5acf149e463d4536453ec978\n",
      "Successfully built asciitree\n",
      "Installing collected packages: asciitree, numcodecs, fasteners, zarr\n",
      "Successfully installed asciitree-0.3.3 fasteners-0.18 numcodecs-0.11.0 zarr-2.14.2\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.9/dist-packages (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.9/dist-packages (from h5py) (1.22.4)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting jiwer\n",
      "  Downloading jiwer-3.0.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.9/dist-packages (from jiwer) (8.1.3)\n",
      "Collecting rapidfuzz==2.13.7\n",
      "  Downloading rapidfuzz-2.13.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
      "Successfully installed jiwer-3.0.1 rapidfuzz-2.13.7\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.10.0\n",
    "!pip install tensorflow==2.10.0\n",
    "!pip install sk-video\n",
    "!pip install scipy\n",
    "!pip install mediapipe\n",
    "!pip install zarr\n",
    "!pip install h5py\n",
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDbyKkVNWD4e"
   },
   "source": [
    "# **Align | Videos | Dataset Maker**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IbnDsMUsiF6N",
    "outputId": "63a8466e-662d-4f04-b364-6780cb1768b7"
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf \n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "from scipy import ndimage\n",
    "import skvideo.io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "sB88Ur_xiTS6"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Align(object):\n",
    "    def __init__(self, absolute_max_string_len=26, label_func=None):\n",
    "        self.label_func = label_func\n",
    "        self.absolute_max_string_len = absolute_max_string_len\n",
    "\n",
    "    def from_file(self, path):\n",
    "        with open(path, 'r',encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        list_of_strings=[]\n",
    "        for i in range(len(lines)):\n",
    "\n",
    "            lines[i]=lines[i].strip()\n",
    "           # print(\"linesss: \",lines[i])\n",
    "            new_array = lines[i].split(' ')\n",
    "            # print(\"new_array: \", new_array)\n",
    "            # print(\"new_array[0]: \", new_array[0])\n",
    "            if(new_array[0]!=''):\n",
    "                list_of_strings.append(new_array[0])\n",
    "                #print(new_array)\n",
    "                #list_of_strings.append(new_array[1])\n",
    "\n",
    "        #code to safe the start and end of the video after removing the silence\n",
    "        if (len(lines) > 2):\n",
    "            length = len(lines)\n",
    "            firstline = lines[0].split(' ')\n",
    "            lastline = lines[length - 1].split(' ')\n",
    "            last=lastline[0]\n",
    "            last=last[1:len(last)]\n",
    "            # print(firstline)\n",
    "            # print(firstline[2])\n",
    "            # print(last)\n",
    "\n",
    "            self.start = firstline[2]\n",
    "            self.end = last\n",
    "            # print(self.start)\n",
    "            # print(self.end)\n",
    "\n",
    "\n",
    "\n",
    "        #print(list_of_strings)\n",
    "        # new_string=''\n",
    "        # for i in range(len(list_of_strings)):\n",
    "        #     if(i<len(list_of_strings)-1):\n",
    "        #         new_string+=list_of_strings[i]+\" \"\n",
    "        #     else:\n",
    "        #         new_string += list_of_strings[i]\n",
    "        # print(new_string)\n",
    "\n",
    "\n",
    "\n",
    "        #align = [(int(y[0])/1000, int(y[1])/1000, y[2]) for y in [x.strip().split(\" \") for x in lines]]\n",
    "        self.build(list_of_strings)\n",
    "        return self\n",
    "\n",
    "    def from_array(self, align):\n",
    "        self.build(align)\n",
    "        return self\n",
    "\n",
    "    def build(self, align):\n",
    "        # self.align = self.strip(align, ['sp','<sil>'])\n",
    "        print(align[1:7])\n",
    "        self.align=align[1:7]\n",
    "        for i in range(len(self.align)) :\n",
    "            print(self.align[i])\n",
    "        self.sentence = self.get_sentence(align[1:7])\n",
    "        self.label = self.get_label(self.sentence)\n",
    "        self.padded_label = self.get_padded_label(self.label)\n",
    "        # print(\"Sentencce: \",self.sentence)\n",
    "        # print(\"label: \", self.label)\n",
    "        # print(\"padded_label: \", self.padded_label)\n",
    "        # print(\"padded_label len: \", len(self.label))\n",
    "    def strip(self, align, items):\n",
    "        return [sub for sub in align if sub[2] not in items]\n",
    "\n",
    "    def get_sentence(self, align):\n",
    "        sentence=''\n",
    "        for i in range(len(self.align)) :\n",
    "            if(i<len(self.align)-1):\n",
    "                sentence+=self.align[i]+\" \"\n",
    "            else:\n",
    "                sentence += self.align[i]\n",
    "\n",
    "\n",
    "        return sentence\n",
    "\n",
    "    def get_label(self, sentence):\n",
    "        return self.label_func(sentence)\n",
    "\n",
    "    def get_padded_label(self, label):\n",
    "        padding = np.ones((self.absolute_max_string_len-len(label))) * -1\n",
    "        return np.concatenate((np.array(label), padding), axis=0)\n",
    "\n",
    "    @property\n",
    "    def word_length(self):\n",
    "        return len(self.sentence.split(\" \"))\n",
    "\n",
    "    @property\n",
    "    def sentence_length(self):\n",
    "        return len(self.sentence)\n",
    "\n",
    "    @property\n",
    "    def label_length(self):\n",
    "        return len(self.label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Video(object):\n",
    "    def __init__(self):\n",
    "        self.mp_holistic = mp.solutions.holistic\n",
    "        self.holistic_model = self.mp_holistic.Holistic(\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "\n",
    "    def getLipLandmarks(self, results):\n",
    "        index = 0\n",
    "        lips_x = []\n",
    "        lips_y = []\n",
    "        for lip_landmarks in results.landmark:\n",
    "            # print(\"x: \",lip_landmarks.x)\n",
    "            # print(\"y: \",lip_landmarks.y)\n",
    "            if (index == 61 or index == 76 or index == 62 or index == 146 or index == 77 or index == 96\n",
    "                    or index == 95 or index == 191 or index == 183 or index == 184 or index == 185 or index == 78\n",
    "                    or index == 306 or index == 292 or index == 291 or index == 308 or index == 324 or index == 415\n",
    "                    or index == 407 or index == 408 or index == 409 or index == 325 or index == 307 or index == 375\n",
    "                    or index == 40 or index == 74 or index == 42 or index == 80 or index == 88 or index == 89 or index == 90\n",
    "                    or index == 91 or index == 39 or index == 73 or index == 41 or index == 81 or index == 178 or index == 179\n",
    "                    or index == 180 or index == 181 or index == 37 or index == 72 or index == 38 or index == 82 or index == 87\n",
    "                    or index == 86 or index == 85 or index == 84 or index == 0 or index == 11 or index == 12 or index == 13\n",
    "                    or index == 14 or index == 15 or index == 16 or index == 17 or index == 267 or index == 302 or index == 268\n",
    "                    or index == 312 or index == 317 or index == 316 or index == 315 or index == 314 or index == 269 or index == 303\n",
    "                    or index == 271 or index == 311 or index == 402 or index == 403 or index == 404 or index == 405 or index == 270\n",
    "                    or index == 304 or index == 272 or index == 310 or index == 318 or index == 319 or index == 320 or index == 321):\n",
    "                # Putting array of landmark attributes in test (Exluding res.visibility)\n",
    "                lips_x.append(lip_landmarks.x)\n",
    "                lips_y.append(lip_landmarks.y)\n",
    "\n",
    "            index += 1  # (Update)To keep track\n",
    "        return lips_x, lips_y\n",
    "\n",
    "    def ApplyModel(self, ImagePath):\n",
    "        frame = ImagePath\n",
    "\n",
    "        # frame = cv2.resize(frame, (800, 600))\n",
    "\n",
    "        # image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results = self.holistic_model.process(frame)\n",
    "        lips_x = []\n",
    "        lips_y = []\n",
    "\n",
    "        if (results.face_landmarks):\n",
    "            lips_x, lips_y = self.getLipLandmarks(results.face_landmarks)\n",
    "            self.prev_lipsx = lips_x\n",
    "            self.prev_lipsy = lips_y\n",
    "            MOUTH_WIDTH = 100\n",
    "            MOUTH_HEIGHT = 50\n",
    "            HORIZONTAL_PAD = 0.05\n",
    "            VERTICAL_PAD = 0.05\n",
    "            # Converting back the RGB image to BGR\n",
    "            # image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Unormalizing lip landmarks\n",
    "            for i in range(len(lips_x)):\n",
    "                lips_x[i] = int(lips_x[i] * frame.shape[1])\n",
    "                lips_y[i] = int(lips_y[i] * frame.shape[0])\n",
    "\n",
    "            # code to draw landmarks on lips\n",
    "            # for i in range(len(lips_x)):\n",
    "            # cv2.circle(frame, (lips_x[i],lips_y[i]), 1, (255, 0, 0), -1)\n",
    "            # plt.imshow(frame)\n",
    "\n",
    "            mouth_left = min(lips_x) * (1.0 - HORIZONTAL_PAD)\n",
    "            mouth_right = max(lips_x) * (1.0 + HORIZONTAL_PAD)\n",
    "            mouth_top = min(lips_y) * (1.0 - VERTICAL_PAD)\n",
    "            mouth_bottom = max(lips_y) * (1.0 + VERTICAL_PAD)\n",
    "\n",
    "            crop_image = frame[int(mouth_top):int(mouth_bottom), int(mouth_left):int(mouth_right)]\n",
    "\n",
    "            newsize = (100, 50)\n",
    "\n",
    "            resized_img = cv2.resize(crop_image, newsize)\n",
    "        else:\n",
    "            crop_image = frame\n",
    "\n",
    "            newsize = (100, 50)\n",
    "\n",
    "            resized_img = cv2.resize(crop_image, newsize)\n",
    "\n",
    "        return resized_img\n",
    "\n",
    "    def from_frames(self, path):\n",
    "        frames = self.get_video_frames(path)\n",
    "        # frames_path = sorted([os.path.join(path, x) for x in os.listdir(path)])\n",
    "        # frames = [ndimage.imread(frame_path) for frame_path in frames_path]\n",
    "        self.handle_type(frames)\n",
    "        return self\n",
    "\n",
    "    def from_video(self, path,start,end):\n",
    "        clip = VideoFileClip(path)\n",
    "\n",
    "        # clipping of the video\n",
    "        # getting video for only starting 10 seconds\n",
    "        clip = clip.subclip(start, end)\n",
    "\n",
    "        # showing clip\n",
    "        #clip.ipython_display(width=280)\n",
    "        paths=path.split('\\\\')\n",
    "        new_path=paths[0:len(paths)-1]\n",
    "        filepath=new_path[0]\n",
    "        count=1\n",
    "        while(count<len(new_path)):\n",
    "            filepath=os.path.join(filepath,new_path[count])\n",
    "            count=count+1\n",
    "        print(\"paths: \",new_path)\n",
    "        newvidgeneratedpath=os.path.join(filepath,'__temp__.mp4')\n",
    "        clip.write_videofile(newvidgeneratedpath)\n",
    "\n",
    "        frames = self.get_video_frames(newvidgeneratedpath)\n",
    "        self.handle_type(frames)\n",
    "        return self\n",
    "\n",
    "    def from_array(self, frames):\n",
    "        self.handle_type(frames)\n",
    "        return self\n",
    "\n",
    "    def handle_type(self, frames):\n",
    "        self.process_frames_face(frames)\n",
    "\n",
    "    def process_frames_face(self, frames):\n",
    "\n",
    "        mouth_frames = self.get_frames_mouth(frames)\n",
    "        print(len(mouth_frames))\n",
    "        if(len(mouth_frames)<75):\n",
    "            sub=75-len(mouth_frames)\n",
    "            odd=False\n",
    "            new_sub = int(sub / 2)\n",
    "            if sub%2==0:\n",
    "                odd=False\n",
    "            else:\n",
    "                odd=True\n",
    "            new_frames=[]\n",
    "            for i in range(new_sub):\n",
    "                new_frames.append(mouth_frames[0])\n",
    "            for i in range(len(mouth_frames)):\n",
    "                new_frames.append(mouth_frames[i])\n",
    "\n",
    "            if(odd==True):\n",
    "                new_sub=new_sub+1\n",
    "            for i in range(new_sub):\n",
    "                new_frames.append(mouth_frames[len(mouth_frames)-1])\n",
    "\n",
    "            print(\"newframes: \", new_frames[0].shape)\n",
    "            mouth_frames = new_frames\n",
    "        else:\n",
    "            print(len(mouth_frames))\n",
    "            mouth_frames = mouth_frames[0:75]\n",
    "            print(\"........................................................THERE ARE MORE THAN 75 FRAMES........................................................................................................................................................\")\n",
    "\n",
    "\n",
    "        #print(\"Mouth frames: \",mouth_frames)\n",
    "        #self.face = np.array(frames)\n",
    "        self.mouth = np.array(mouth_frames)\n",
    "        self.set_data(mouth_frames)\n",
    "\n",
    "    def process_frames_mouth(self, frames):\n",
    "        self.face = np.array(frames)\n",
    "        self.mouth = np.array(frames)\n",
    "        self.set_data(frames)\n",
    "\n",
    "    def get_frames_mouth(self, frames):\n",
    "        fname = []\n",
    "        for i in range(len(frames)):\n",
    "            # im_cv = cv2.imread(frames[i], cv2.IMREAD_COLOR)\n",
    "            # im_rgb = cv2.cvtColor(im_cv, cv2.COLOR_BGR2RGB)\n",
    "            # frame2=self.edit_module(im_rgb)\n",
    "            cropped_img = self.ApplyModel(frames[i])\n",
    "            fname.append(cropped_img)\n",
    "        return fname\n",
    "\n",
    "    def get_video_frames(self, path):\n",
    "        videogen = skvideo.io.vreader(path)\n",
    "\n",
    "        frames = np.array([frame for frame in videogen])\n",
    "        #print(\"frames: \",frames)\n",
    "        return frames\n",
    "\n",
    "    def set_data(self, frames):\n",
    "        data_frames = []\n",
    "        for frame in frames:\n",
    "            frame = frame.swapaxes(0, 1)  # swap width and height to form format W x H x C\n",
    "            if len(frame.shape) < 3:\n",
    "                frame = np.array([frame]).swapaxes(0, 2).swapaxes(0, 1)  # Add grayscale channel\n",
    "            data_frames.append(frame)\n",
    "        frames_n = len(data_frames)\n",
    "        data_frames = np.array(data_frames)  # T x W x H x C\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            data_frames = np.rollaxis(data_frames, 3)  # C x T x W x H\n",
    "        self.data = data_frames\n",
    "        #print(\"self.data: \",self.data.shape)\n",
    "        self.length = frames_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WJs55wP8iw7G"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "class datasetMaker:\n",
    "  def __init__(self,videos_path,align_path,img_c,img_w,img_h,frames_n,max_length):\n",
    "    self.path=videos_path\n",
    "    self.align_path=align_path\n",
    "    self.blank_label    = 27\n",
    "    self.img_c          = img_c\n",
    "    self.img_w          = img_w\n",
    "    self.img_h          = img_h\n",
    "    self.frames_n       = frames_n\n",
    "    self.absolute_max_string_len = max_length\n",
    "  \n",
    "        \n",
    "  def enumerate_videos(self, path):\n",
    "        video_list = []\n",
    "        print(path)\n",
    "        #print(\"dishfisdfh\")\n",
    "        count1=0\n",
    "        count2=20\n",
    "        count=0\n",
    "        for video_path in glob.glob(path):\n",
    "            \n",
    "            if(count>=count1 and count<count2):\n",
    "              count+=1\n",
    "              try:\n",
    "                  if os.path.isfile(video_path):\n",
    "                      print(video_path)\n",
    "                      video = Video().from_video(video_path)\n",
    "                  else:\n",
    "                      #print(\"yrs\")\n",
    "                      video = Video().from_frames(video_path)\n",
    "              except AttributeError as err:\n",
    "                  raise err\n",
    "              except:\n",
    "                  print (\"Error loading video: \")+video_path\n",
    "                  continue\n",
    "              print(\"video shape: \",video.data.shape)\n",
    "              if K.image_data_format() == 'channels_first' and video.data.shape != (self.img_c,self.frames_n,self.img_w,self.img_h):\n",
    "                  print (\"Video \")+video_path+\" has incorrect shape \"+str(video.data.shape)+\", must be \"+str((self.img_c,self.frames_n,self.img_w,self.img_h))+\"\"\n",
    "                  continue\n",
    "              if K.image_data_format() != 'channels_first' and video.data.shape != (self.frames_n,self.img_w,self.img_h,self.img_c):\n",
    "                  print (\"Video \")+video_path+\" has incorrect shape \"+str(video.data.shape)+\", must be \"+str((self.frames_n,self.img_w,self.img_h,self.img_c))+\"\"\n",
    "                  continue\n",
    "              video_list.append(video_path)\n",
    "              print(\"count: \",count)\n",
    "            else:\n",
    "              break\n",
    "        return video_list\n",
    "  def get_align(self, _id):\n",
    "        return self.align_hash[_id]\n",
    "  def enumerate_align_hash(self, video_list):\n",
    "        self.align_hash = {}\n",
    "        for video_path in video_list:\n",
    "            video_id = os.path.splitext(video_path)[0].split('/')[-1]\n",
    "            align_path = os.path.join(self.align_path, video_id)+\".align\"\n",
    "            self.align_hash[video_id] = Align(self.absolute_max_string_len, text_to_labels).from_file(align_path)\n",
    "        return self.align_hash\n",
    "  def get_batch(self, video_list, align_hash):\n",
    "        X_data_path = video_list\n",
    "        X_data = []\n",
    "        Y_data = []\n",
    "        label_length = []\n",
    "        input_length = []\n",
    "        source_str = []\n",
    "        for path in X_data_path:\n",
    "            #print(\"path: \",path)\n",
    "            video = Video().from_video(path)\n",
    "            temp=path.split('/')[-1]\n",
    "            t=temp.split('.')\n",
    "            #print(\"t: \",t)\n",
    "            align =self.get_align(t[0])\n",
    "            video_unpadded_length = video.length\n",
    "            X_data.append(video.data)\n",
    "            Y_data.append(align.padded_label)\n",
    "            label_length.append(align.label_length) # CHANGED [A] -> A, CHECK!\n",
    "            # input_length.append([video_unpadded_length - 2]) # 2 first frame discarded\n",
    "            input_length.append(video.length) # Just use the video padded length to avoid CTC No path found error (v_len < a_len)\n",
    "            source_str.append(align.sentence) # CHANGED [A] -> A, CHECK!\n",
    "\n",
    "        source_str = np.array(source_str)\n",
    "        label_length = np.array(label_length)\n",
    "        input_length = np.array(input_length)\n",
    "        Y_data = np.array(Y_data)\n",
    "        X_data = np.array(X_data).astype(np.float32) / 255 # Normalize image data to [0,1], TODO: mean normalization over training data\n",
    "\n",
    "        inputs = {'the_input': X_data,\n",
    "                  'the_labels': Y_data,\n",
    "                  'input_length': input_length,\n",
    "                  'label_length': label_length,\n",
    "                  'source_str': source_str  # used for visualization only\n",
    "                  }\n",
    "        outputs = {'ctc': np.zeros([len(video_list)])}  # dummy data for dummy loss function\n",
    "\n",
    "        return (inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CZpbXEu5Oyht"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 144\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentence\u001b[39m(\u001b[38;5;28mself\u001b[39m, sentence):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m untokenize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorrections(tokenize(sentence)))\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtranslate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bleu_score\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01meditdistance\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "def _decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1):\n",
    "    \"\"\"Decodes the output of a softmax.\n",
    "    Can use either greedy search (also known as best path)\n",
    "    or a constrained dictionary search.\n",
    "    # Arguments\n",
    "        y_pred: tensor `(samples, time_steps, num_categories)`\n",
    "            containing the prediction, or output of the softmax.\n",
    "        input_length: tensor `(samples, )` containing the sequence length for\n",
    "            each batch item in `y_pred`.\n",
    "        greedy: perform much faster best-path search if `true`.\n",
    "            This does not use a dictionary.\n",
    "        beam_width: if `greedy` is `false`: a beam search decoder will be used\n",
    "            with a beam of this width.\n",
    "        top_paths: if `greedy` is `false`,\n",
    "            how many of the most probable paths will be returned.\n",
    "    # Returns\n",
    "        Tuple:\n",
    "            List: if `greedy` is `true`, returns a list of one element that\n",
    "                contains the decoded sequence.\n",
    "                If `false`, returns the `top_paths` most probable\n",
    "                decoded sequences.\n",
    "                Important: blank labels are returned as `-1`.\n",
    "            Tensor `(top_paths, )` that contains\n",
    "                the log probability of each decoded sequence.\n",
    "    \"\"\"\n",
    "    decoded = K.ctc_decode(y_pred=y_pred, input_length=input_length,\n",
    "                           greedy=greedy, beam_width=beam_width, top_paths=top_paths)\n",
    "    print(\"decode: \",decoded)\n",
    "    paths = [path.eval(session=K.get_session()) for path in decoded[0]]\n",
    "    logprobs  = decoded[1].eval(session=K.get_session())\n",
    "\n",
    "    return (paths, logprobs)\n",
    "\n",
    "def decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1, **kwargs):\n",
    "    language_model = kwargs.get('language_model', None)\n",
    "\n",
    "    paths, logprobs = _decode(y_pred=y_pred, input_length=input_length,\n",
    "                              greedy=greedy, beam_width=beam_width, top_paths=top_paths)\n",
    "    if language_model is not None:\n",
    "        # TODO: compute using language model\n",
    "        raise NotImplementedError(\"Language model search is not implemented yet\")\n",
    "    else:\n",
    "        # simply output highest probability sequence\n",
    "        # paths has been sorted from the start\n",
    "        result = paths[0]\n",
    "    return result\n",
    "\n",
    "class Decoder(object):\n",
    "    def __init__(self, greedy=True, beam_width=100, top_paths=1, **kwargs):\n",
    "        self.greedy         = greedy\n",
    "        self.beam_width     = beam_width\n",
    "        self.top_paths      = top_paths\n",
    "        self.language_model = kwargs.get('language_model', None)\n",
    "        self.postprocessors = kwargs.get('postprocessors', [])\n",
    "\n",
    "    def decode(self, y_pred, input_length):\n",
    "        decoded = decode(y_pred, input_length, greedy=self.greedy, beam_width=self.beam_width,\n",
    "                         top_paths=self.top_paths, language_model=self.language_model)\n",
    "        preprocessed = []\n",
    "        for output in decoded:\n",
    "            out = output\n",
    "            for postprocessor in self.postprocessors:\n",
    "                out = postprocessor(out)\n",
    "            preprocessed.append(out)\n",
    "\n",
    "        return preprocessed\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "# Source: https://github.com/commonsense/metanl/blob/master/metanl/token_utils.py\n",
    "def untokenize(words):\n",
    "    \"\"\"\n",
    "    Untokenizing a text undoes the tokenizing operation, restoring\n",
    "    punctuation and spaces to the places that people expect them to be.\n",
    "    Ideally, `untokenize(tokenize(text))` should be identical to `text`,\n",
    "    except for line breaks.\n",
    "    \"\"\"\n",
    "    text = ' '.join(words)\n",
    "    step1 = text.replace(\"`` \", '\"').replace(\" ''\", '\"').replace('. . .',  '...')\n",
    "    step2 = step1.replace(\" ( \", \" (\").replace(\" ) \", \") \")\n",
    "    step3 = re.sub(r' ([.,:;?!%]+)([ \\'\"`])', r\"\\1\\2\", step2)\n",
    "    step4 = re.sub(r' ([.,:;?!%]+)$', r\"\\1\", step3)\n",
    "    step5 = step4.replace(\" '\", \"'\").replace(\" n't\", \"n't\").replace(\n",
    "         \"can not\", \"cannot\")\n",
    "    step6 = step5.replace(\" ` \", \" '\")\n",
    "    return step6.strip()\n",
    "\n",
    "# Source: https://stackoverflow.com/questions/367155/splitting-a-string-into-words-and-punctuation\n",
    "def tokenize(text):\n",
    "    return re.findall(r\"\\w+|[^\\w\\s]\", text, re.UNICODE)\n",
    "\n",
    "# Source: http://norvig.com/spell-correct.html (with some modifications)\n",
    "class Spell(object):\n",
    "    def __init__(self, path):\n",
    "        self.dictionary = Counter(list(string.punctuation) + self.words(open(path).read()))\n",
    "\n",
    "    def words(self, text):\n",
    "        return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "    def P(self, word, N=None):\n",
    "        \"Probability of `word`.\"\n",
    "        if N is None:\n",
    "            N = sum(self.dictionary.values())\n",
    "        return self.dictionary[word] / N\n",
    "\n",
    "    def correction(self, word):\n",
    "        \"Most probable spelling correction for word.\"\n",
    "        return max(self.candidates(word), key=self.P)\n",
    "\n",
    "    def candidates(self, word):\n",
    "        \"Generate possible spelling corrections for word.\"\n",
    "        return (self.known([word]) or self.known(self.edits1(word)) or self.known(self.edits2(word)) or [word])\n",
    "\n",
    "    def known(self, words):\n",
    "        \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "        return set(w for w in words if w in self.dictionary)\n",
    "\n",
    "    def edits1(self, word):\n",
    "        \"All edits that are one edit away from `word`.\"\n",
    "        letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "        deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "        replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "        inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "    def edits2(self, word):\n",
    "        \"All edits that are two edits away from `word`.\"\n",
    "        return (e2 for e1 in self.edits1(word) for e2 in self.edits1(e1))\n",
    "\n",
    "    # Correct words\n",
    "    def corrections(self, words):\n",
    "        return [self.correction(word) for word in words]\n",
    "\n",
    "    # Correct sentence\n",
    "    def sentence(self, sentence):\n",
    "        return untokenize(self.corrections(tokenize(sentence)))\n",
    "\n",
    "from nltk.translate import bleu_score\n",
    "import numpy as np\n",
    "import editdistance\n",
    "import keras\n",
    "import csv\n",
    "import os\n",
    "import numpy\n",
    "import doctest\n",
    "\n",
    "\n",
    "#helpers\n",
    "def text_to_labels(text):\n",
    "    letters=['ا', 'ب', 'پ', 'ت', 'ٹ', 'ث', 'ج', 'چ', 'ح', 'خ', 'د', 'ڈ', 'ذ', 'ر', 'ڑ', 'ز', 'ژ', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ',\n",
    "     'ع', 'غ', 'ف', 'ک', 'گ', 'ل', 'م', 'ن', 'و', 'ہ', 'ﮩ', 'ﮨ', 'ھ', 'ء', 'ی', 'ے']\n",
    "    unicode=[1575, 1576, 1662, 1578, 1657, 1579, 1580, 1670, 1581, 1582, 1583, 1672, 1584, 1585, 1586, 1688, 1587, 1588, 1589,\n",
    "     1590, 1591, 1592, 1593, 1594, 1601, 1602, 1705, 1711, 1604, 1605, 1606, 1608, 1729, 64425, 64424, 1726, 1569, 1740,\n",
    "     1746]\n",
    "    maps=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
    "     31, 32, 33, 34, 35, 36, 37, 38]\n",
    "    ret = []\n",
    "    # digits=[]\n",
    "    # order\n",
    "    for char in text:\n",
    "        if char == ' ':\n",
    "            ret.append(39)\n",
    "        else:\n",
    "            for m in range(len(unicode)):\n",
    "                if ord(char)==unicode[m]:\n",
    "                    ret.append(maps[m])\n",
    "\n",
    "    return ret\n",
    "\n",
    "def labels_to_text(labels):\n",
    "    letters = ['ا', 'ب', 'پ', 'ت', 'ٹ', 'ث', 'ج', 'چ', 'ح', 'خ', 'د', 'ڈ', 'ذ', 'ر', 'ڑ', 'ز', 'ژ', 'س', 'ش', 'ص', 'ض',\n",
    "               'ط', 'ظ',\n",
    "               'ع', 'غ', 'ف', 'ک', 'گ', 'ل', 'م', 'ن', 'و', 'ہ', 'ﮩ', 'ﮨ', 'ھ', 'ء', 'ی', 'ے']\n",
    "    unicode = [1575, 1576, 1662, 1578, 1657, 1579, 1580, 1670, 1581, 1582, 1583, 1672, 1584, 1585, 1586, 1688, 1587,\n",
    "               1588, 1589,\n",
    "               1590, 1591, 1592, 1593, 1594, 1601, 1602, 1705, 1711, 1604, 1605, 1606, 1608, 1729, 64425, 64424, 1726,\n",
    "               1569, 1740,\n",
    "               1746]\n",
    "    maps = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,\n",
    "            29, 30,\n",
    "            31, 32, 33, 34, 35, 36, 37, 38]\n",
    "    # 26 is space, 27 is CTC blank char\n",
    "    text = ''\n",
    "    for c in labels:\n",
    "        if c==39:\n",
    "            text += ' '\n",
    "        else:\n",
    "            for i in range(len(maps)):\n",
    "                if(c==maps[i]):\n",
    "                    text+=letters[i]\n",
    "    return text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/Images\n"
     ]
    }
   ],
   "source": [
    "cd Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m0_zarr\u001b[0m/  \u001b[01;34m1_zarr\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mYSdzESF9kqj"
   },
   "outputs": [],
   "source": [
    "import zarr\n",
    "def Save_files_as_zarr(data,count,directory):\n",
    "  path='/tf/Images/'\n",
    "  zarr.save(path+directory+'_zarr/'+count+'/the_input.zarr',data[0]['the_input'])\n",
    "  zarr.save(path+directory+'_zarr/'+count+'/the_labels.zarr',data[0]['the_labels'])\n",
    "  zarr.save(path+directory+'_zarr/'+count+'/the_input_length.zarr',data[0]['input_length'])\n",
    "  zarr.save(path+directory+'_zarr/'+count+'/the_label_length.zarr',data[0]['label_length'])\n",
    "  zarr.save(path+directory+'_zarr/'+count+'/ctc.zarr',data[1]['ctc']) \n",
    "\n",
    "def Load_files_from_zarr(count,directory):\n",
    "  path='/tf/Images/'\n",
    "  input = zarr.load(path+directory+'_zarr/'+count+'/the_input.zarr')\n",
    "  label = zarr.load(path+directory+'_zarr/'+count+'/the_labels.zarr')\n",
    "  input_length = zarr.load(path+directory+'_zarr/'+count+'/the_input_length.zarr')\n",
    "  label_length = zarr.load(path+directory+'_zarr/'+count+'/the_label_length.zarr')\n",
    "  ctc = zarr.load(path+directory+'_zarr/'+count+'/ctc.zarr')\n",
    "  inputs = {'the_input': input,\n",
    "                  'the_labels': label,\n",
    "                  'input_length': input_length,\n",
    "                  'label_length': label_length,\n",
    "                  #'source_str': source_str  # used for visualization only\n",
    "            }\n",
    "  outputs = {'ctc': ctc}  # dummy data for dummy loss function\n",
    "  return(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h5rOZ71a-D3P",
    "outputId": "c474d9e1-6290-4a06-ab9f-c2dc6dd171b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_data=None\n",
    "for i in range(2):\n",
    "  print(i+1)\n",
    "  data=Load_files_from_zarr(str(i+1),'0')\n",
    "  if(i==0):\n",
    "    new_data=data\n",
    "  else:\n",
    "    arr1=data[0]['the_input']\n",
    "    arr2=new_data[0]['the_input']\n",
    "    joined=np.concatenate((arr1,arr2),axis=0)\n",
    "    joined2=np.concatenate((data[0]['the_labels'],new_data[0]['the_labels']),axis=0)\n",
    "    joined3=np.concatenate((data[0]['input_length'],new_data[0]['input_length']),axis=0)\n",
    "    joined4=np.concatenate((data[0]['label_length'],new_data[0]['label_length']),axis=0)\n",
    "    joined5=np.concatenate((data[1]['ctc'],new_data[1]['ctc']),axis=0)\n",
    "    new_data[0]['the_input']=joined\n",
    "    new_data[0]['the_labels']=joined2\n",
    "    new_data[0]['input_length']=joined3\n",
    "    new_data[0]['label_length']=joined4\n",
    "    new_data[1]['ctc']=joined5\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NDfPl1droBXW",
    "outputId": "1d27ff76-af04-4a13-c06f-5205037cfa62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "CPU times: user 1.26 s, sys: 496 ms, total: 1.75 s\n",
      "Wall time: 7.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val_data=None\n",
    "for i in range(3):\n",
    "  print(i+1)\n",
    "  data=Load_files_from_zarr(str(i+1),'3')\n",
    "  if(i==0):\n",
    "    val_data=data\n",
    "  else:\n",
    "    arr1=data[0]['the_input']\n",
    "    arr2=val_data[0]['the_input']\n",
    "    joined=np.concatenate((arr1,arr2),axis=0)\n",
    "    joined2=np.concatenate((data[0]['the_labels'],val_data[0]['the_labels']),axis=0)\n",
    "    joined3=np.concatenate((data[0]['input_length'],val_data[0]['input_length']),axis=0)\n",
    "    joined4=np.concatenate((data[0]['label_length'],val_data[0]['label_length']),axis=0)\n",
    "    joined5=np.concatenate((data[1]['ctc'],val_data[1]['ctc']),axis=0)\n",
    "    val_data[0]['the_input']=joined\n",
    "    val_data[0]['the_labels']=joined2\n",
    "    val_data[0]['input_length']=joined3\n",
    "    val_data[0]['label_length']=joined4\n",
    "    val_data[1]['ctc']=joined5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[0]['the_input']=new_data[0]['the_input'][0:3]\n",
    "new_data[0]['the_labels']=new_data[0]['the_labels'][0:3]\n",
    "new_data[0]['input_length']=new_data[0]['input_length'][0:3]\n",
    "new_data[0]['label_length']=new_data[0]['label_length'][0:3]\n",
    "new_data[1]['ctc']=new_data[1]['ctc'][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ip9EPFGVNMrq",
    "outputId": "49541b0f-8d51-42e0-f942-b14102fd8999"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 75, 100, 50, 3)\n",
      "(3, 29)\n",
      "(3,)\n",
      "(3,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "print(new_data[0]['the_input'].shape)\n",
    "print(new_data[0]['the_labels'].shape)\n",
    "print(new_data[0]['input_length'].shape)\n",
    "print(new_data[0]['label_length'].shape)\n",
    "print(new_data[1]['ctc'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QF9HtJOXWUDT"
   },
   "source": [
    "# **Model Compilation and Build**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "x7iyah_VLIa6"
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv3D, ZeroPadding3D\n",
    "from keras.layers.pooling import MaxPooling3D\n",
    "from keras.layers.core import Dense, Activation, SpatialDropout3D, Flatten\n",
    "from keras.layers import Bidirectional, TimeDistributed\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.core import Lambda\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mwk11EYDb4ge"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "def _decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1):\n",
    "    \"\"\"Decodes the output of a softmax.\n",
    "    Can use either greedy search (also known as best path)\n",
    "    or a constrained dictionary search.\n",
    "    # Arguments\n",
    "        y_pred: tensor `(samples, time_steps, num_categories)`\n",
    "            containing the prediction, or output of the softmax.\n",
    "        input_length: tensor `(samples, )` containing the sequence length for\n",
    "            each batch item in `y_pred`.\n",
    "        greedy: perform much faster best-path search if `true`.\n",
    "            This does not use a dictionary.\n",
    "        beam_width: if `greedy` is `false`: a beam search decoder will be used\n",
    "            with a beam of this width.\n",
    "        top_paths: if `greedy` is `false`,\n",
    "            how many of the most probable paths will be returned.\n",
    "    # Returns\n",
    "        Tuple:\n",
    "            List: if `greedy` is `true`, returns a list of one element that\n",
    "                contains the decoded sequence.\n",
    "                If `false`, returns the `top_paths` most probable\n",
    "                decoded sequences.\n",
    "                Important: blank labels are returned as `-1`.\n",
    "            Tensor `(top_paths, )` that contains\n",
    "                the log probability of each decoded sequence.\n",
    "    \"\"\"\n",
    "    decoded = K.ctc_decode(y_pred=y_pred, input_length=input_length,\n",
    "                           greedy=greedy, beam_width=beam_width, top_paths=top_paths)\n",
    "    paths = [path.eval(session=K.get_session()) for path in decoded[0]]\n",
    "    logprobs  = decoded[1].eval(session=K.get_session())\n",
    "\n",
    "    return (paths, logprobs)\n",
    "\n",
    "def decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1, **kwargs):\n",
    "    language_model = kwargs.get('language_model', None)\n",
    "\n",
    "    paths, logprobs = _decode(y_pred=y_pred, input_length=input_length,\n",
    "                              greedy=greedy, beam_width=beam_width, top_paths=top_paths)\n",
    "    if language_model is not None:\n",
    "        # TODO: compute using language model\n",
    "        raise NotImplementedError(\"Language model search is not implemented yet\")\n",
    "    else:\n",
    "        # simply output highest probability sequence\n",
    "        # paths has been sorted from the start\n",
    "        result = paths[0]\n",
    "    return result\n",
    "\n",
    "class Decoder(object):\n",
    "    def __init__(self, greedy=True, beam_width=100, top_paths=1, **kwargs):\n",
    "        self.greedy         = greedy\n",
    "        self.beam_width     = beam_width\n",
    "        self.top_paths      = top_paths\n",
    "        self.language_model = kwargs.get('language_model', None)\n",
    "        self.postprocessors = kwargs.get('postprocessors', [])\n",
    "\n",
    "    def decode(self, y_pred, input_length):\n",
    "        decoded = decode(y_pred, input_length, greedy=self.greedy, beam_width=self.beam_width,\n",
    "                         top_paths=self.top_paths, language_model=self.language_model)\n",
    "        preprocessed = []\n",
    "        for output in decoded:\n",
    "            out = output\n",
    "            for postprocessor in self.postprocessors:\n",
    "                out = postprocessor(out)\n",
    "            preprocessed.append(out)\n",
    "\n",
    "        return preprocessed\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "# Source: https://github.com/commonsense/metanl/blob/master/metanl/token_utils.py\n",
    "def untokenize(words):\n",
    "    \"\"\"\n",
    "    Untokenizing a text undoes the tokenizing operation, restoring\n",
    "    punctuation and spaces to the places that people expect them to be.\n",
    "    Ideally, `untokenize(tokenize(text))` should be identical to `text`,\n",
    "    except for line breaks.\n",
    "    \"\"\"\n",
    "    text = ' '.join(words)\n",
    "    step1 = text.replace(\"`` \", '\"').replace(\" ''\", '\"').replace('. . .',  '...')\n",
    "    step2 = step1.replace(\" ( \", \" (\").replace(\" ) \", \") \")\n",
    "    step3 = re.sub(r' ([.,:;?!%]+)([ \\'\"`])', r\"\\1\\2\", step2)\n",
    "    step4 = re.sub(r' ([.,:;?!%]+)$', r\"\\1\", step3)\n",
    "    step5 = step4.replace(\" '\", \"'\").replace(\" n't\", \"n't\").replace(\n",
    "         \"can not\", \"cannot\")\n",
    "    step6 = step5.replace(\" ` \", \" '\")\n",
    "    return step6.strip()\n",
    "\n",
    "# Source: https://stackoverflow.com/questions/367155/splitting-a-string-into-words-and-punctuation\n",
    "def tokenize(text):\n",
    "    return re.findall(r\"\\w+|[^\\w\\s]\", text, re.UNICODE)\n",
    "\n",
    "# Source: http://norvig.com/spell-correct.html (with some modifications)\n",
    "class Spell(object):\n",
    "    def __init__(self, path):\n",
    "        self.dictionary = Counter(list(string.punctuation) + self.words(open(path).read()))\n",
    "\n",
    "    def words(self, text):\n",
    "        return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "    def P(self, word, N=None):\n",
    "        \"Probability of `word`.\"\n",
    "        if N is None:\n",
    "            N = sum(self.dictionary.values())\n",
    "        return self.dictionary[word] / N\n",
    "\n",
    "    def correction(self, word):\n",
    "        \"Most probable spelling correction for word.\"\n",
    "        return max(self.candidates(word), key=self.P)\n",
    "\n",
    "    def candidates(self, word):\n",
    "        \"Generate possible spelling corrections for word.\"\n",
    "        return (self.known([word]) or self.known(self.edits1(word)) or self.known(self.edits2(word)) or [word])\n",
    "\n",
    "    def known(self, words):\n",
    "        \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "        return set(w for w in words if w in self.dictionary)\n",
    "\n",
    "    def edits1(self, word):\n",
    "        \"All edits that are one edit away from `word`.\"\n",
    "        letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "        deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "        replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "        inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "    def edits2(self, word):\n",
    "        \"All edits that are two edits away from `word`.\"\n",
    "        return (e2 for e1 in self.edits1(word) for e2 in self.edits1(e1))\n",
    "\n",
    "    # Correct words\n",
    "    def corrections(self, words):\n",
    "        return [self.correction(word) for word in words]\n",
    "\n",
    "    # Correct sentence\n",
    "    def sentence(self, sentence):\n",
    "        return untokenize(self.corrections(tokenize(sentence)))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "import csv\n",
    "import os\n",
    "import numpy\n",
    "import doctest\n",
    "\n",
    "def wer(r, h):\n",
    "    \"\"\"\n",
    "    Source: https://martin-thoma.com/word-error-rate-calculation/\n",
    "    Calculation of WER with Levenshtein distance.\n",
    "    Works only for iterables up to 254 elements (uint8).\n",
    "    O(nm) time ans space complexity.\n",
    "    Parameters\n",
    "    ----------\n",
    "    r : list\n",
    "    h : list\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "    Examples\n",
    "    --------\n",
    "    >>> wer(\"who is there\".split(), \"is there\".split())\n",
    "    1\n",
    "    >>> wer(\"who is there\".split(), \"\".split())\n",
    "    3\n",
    "    >>> wer(\"\".split(), \"who is there\".split())\n",
    "    3\n",
    "    \"\"\"\n",
    "    # initialisation\n",
    "    d = numpy.zeros((len(r)+1)*(len(h)+1), dtype=numpy.uint8)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                d[0][j] = j\n",
    "            elif j == 0:\n",
    "                d[i][0] = i\n",
    "\n",
    "    # computation\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "            else:\n",
    "                substitution = d[i-1][j-1] + 1\n",
    "                insertion    = d[i][j-1] + 1\n",
    "                deletion     = d[i-1][j] + 1\n",
    "                d[i][j] = min(substitution, insertion, deletion)\n",
    "\n",
    "    return d[len(r)][len(h)]\n",
    "\n",
    "def wer_sentence(r, h):\n",
    "    return wer(r.split(), h.split())\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    doctest.testmod()\n",
    "\n",
    "class Statistics(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, model_container, generator, decoder, num_samples_stats=256, output_dir=None):\n",
    "        self.model_container = model_container\n",
    "        self.output_dir = output_dir\n",
    "        self.generator = generator\n",
    "        self.num_samples_stats = num_samples_stats\n",
    "        self.decoder = decoder\n",
    "        if output_dir is not None and not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    def get_statistics(self, num):\n",
    "        num_left = num\n",
    "        data = []\n",
    "\n",
    "        while num_left > 0:\n",
    "            output_batch    = next(self.generator)[0]\n",
    "            num_proc        = min(output_batch['the_input'].shape[0], num_left)\n",
    "            y_pred          = self.model_container.predict(output_batch['the_input'][0:num_proc])\n",
    "            input_length    = output_batch['input_length'][0:num_proc]\n",
    "            decoded_res     = self.decoder.decode(y_pred, input_length)\n",
    "\n",
    "            for j in range(0, num_proc):\n",
    "                data.append((decoded_res[j], output_batch['source_str'][j]))\n",
    "\n",
    "            num_left -= num_proc\n",
    "\n",
    "        mean_cer, mean_cer_norm    = self.get_mean_character_error_rate(data)\n",
    "        mean_wer, mean_wer_norm    = self.get_mean_word_error_rate(data)\n",
    "        mean_bleu, mean_bleu_norm  = self.get_mean_bleu_score(data)\n",
    "\n",
    "        return {\n",
    "            'samples': num,\n",
    "            'cer': (mean_cer, mean_cer_norm),\n",
    "            'wer': (mean_wer, mean_wer_norm),\n",
    "            'bleu': (mean_bleu, mean_bleu_norm)\n",
    "        }\n",
    "\n",
    "    def get_mean_tuples(self, data, individual_length, func):\n",
    "        total       = 0.0\n",
    "        total_norm  = 0.0\n",
    "        length      = len(data)\n",
    "        for i in range(0, length):\n",
    "            val         = float(func(data[i][0], data[i][1]))\n",
    "            total      += val\n",
    "            total_norm += val / individual_length\n",
    "        return (total/length, total_norm/length)\n",
    "\n",
    "    def get_mean_character_error_rate(self, data):\n",
    "        mean_individual_length = np.mean([len(pair[1]) for pair in data])\n",
    "        return self.get_mean_tuples(data, mean_individual_length, editdistance.eval)\n",
    "\n",
    "    def get_mean_word_error_rate(self, data):\n",
    "        mean_individual_length = np.mean([len(pair[1].split()) for pair in data])\n",
    "        return self.get_mean_tuples(data, mean_individual_length, wer_sentence)\n",
    "\n",
    "    def get_mean_bleu_score(self, data):\n",
    "        wrapped_data = [([reference],hypothesis) for reference,hypothesis in data]\n",
    "        return self.get_mean_tuples(wrapped_data, 1.0, bleu_score.sentence_bleu)\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        pass\n",
    "        #with open(os.path.join(self.output_dir, 'stats.csv'), 'w') as csvfile:\n",
    "         #   print(csvfile)\n",
    "          #  csvw = csv.writer(csvfile)\n",
    "\n",
    "           # csvw.writerow([\"Epoch\", \"Samples\", \"Mean CER\", \"Mean CER (Norm)\", \"Mean WER\", \"Mean WER (Norm)\", \"Mean BLEU\", \"Mean BLEU (Norm)\"])\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        stats = self.get_statistics(self.num_samples_stats)\n",
    "\n",
    "        print('\\n\\n[Epoch %d] Out of %d samples: [CER: %.3f - %.3f] [WER: %.3f - %.3f] [BLEU: %.3f - %.3f]\\n'\n",
    "              % (epoch, stats['samples'], stats['cer'][0], stats['cer'][1], stats['wer'][0], stats['wer'][1], stats['bleu'][0], stats['bleu'][1]))\n",
    "\n",
    "        #if self.output_dir is not None:\n",
    "         #   with open(os.path.join(self.output_dir, 'stats.csv'), 'ab') as csvfile:\n",
    "          #      csvw = csv.writer(csvfile)\n",
    "           #     csvw.writerow([epoch, stats['samples'],\n",
    "            #                   \"{0:.5f}\".format(stats['cer'][0]), \"{0:.5f}\".format(stats['cer'][1]),\n",
    "             #                  \"{0:.5f}\".format(stats['wer'][0]), \"{0:.5f}\".format(stats['wer'][1]),\n",
    "              #                 \"{0:.5f}\".format(stats['bleu'][0]), \"{0:.5f}\".format(stats['bleu'][1])])\n",
    "\n",
    "\n",
    "class Visualize(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, output_dir, model_container, generator, decoder, num_display_sentences=10):\n",
    "        self.model_container = model_container\n",
    "        self.output_dir = output_dir\n",
    "        self.generator = generator\n",
    "        self.num_display_sentences = num_display_sentences\n",
    "        self.decoder = decoder\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        output_batch = next(self.generator)[0]\n",
    "\n",
    "        y_pred       = self.model_container.predict(output_batch['the_input'][0:self.num_display_sentences])\n",
    "        input_length = output_batch['input_length'][0:self.num_display_sentences]\n",
    "        res          = self.decoder.decode(y_pred, input_length)\n",
    "\n",
    "     #with open(os.path.join(self.output_dir, 'e%02d.csv' % (epoch)), 'wb') as csvfile:\n",
    "      #      csvw = csv.writer(csvfile)\n",
    "       #     csvw.writerow([\"Truth\", \"Decoded\"])\n",
    "        #    for i in range(self.num_display_sentences):\n",
    "         #       csvw.writerow([output_batch['source_str'][i], res[i]])'''\n",
    "#helpers\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# Actual loss calculation\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # From Keras example image_ocr.py:\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    # y_pred = y_pred[:, 2:, :]\n",
    "    y_pred = y_pred[:, :, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers import Input\n",
    "\n",
    "# CTC Layer implementation using Lambda layer\n",
    "# (because Keras doesn't support extra prams on loss function)\n",
    "def CTC(name, args):\n",
    "\treturn Lambda(ctc_lambda_func, output_shape=(1,), name=name)(args)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "def build(img_c=3, img_w=100, img_h=50, frames_n=75, absolute_max_string_len=29, output_size=43):\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            input_shape = (img_c, frames_n, img_w, img_h)\n",
    "        else:\n",
    "            input_shape = (frames_n, img_w, img_h, img_c)\n",
    "\n",
    "        input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "\n",
    "        zero1 = ZeroPadding3D(padding=(1, 2, 2), name='zero1')(input_data)\n",
    "        conv1 = Conv3D(32, (3, 5, 5), strides=(1, 2, 2), kernel_initializer='he_normal', name='conv1')(zero1)\n",
    "        batc1 = BatchNormalization(name='batc1')(conv1)\n",
    "        actv1 = Activation('relu', name='actv1')(batc1)\n",
    "        drop1 = SpatialDropout3D(0.5)(actv1)\n",
    "        maxp1 = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max1')(drop1)\n",
    "\n",
    "        zero2 = ZeroPadding3D(padding=(1, 2, 2), name='zero2')(maxp1)\n",
    "        conv2 = Conv3D(64, (3, 5, 5), strides=(1, 1, 1), kernel_initializer='he_normal', name='conv2')(zero2)\n",
    "        batc2 = BatchNormalization(name='batc2')(conv2)\n",
    "        actv2 = Activation('relu', name='actv2')(batc2)\n",
    "        drop2 = SpatialDropout3D(0.5)(actv2)\n",
    "        maxp2 = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max2')(drop2)\n",
    "\n",
    "        zero3 = ZeroPadding3D(padding=(1, 1, 1), name='zero3')(maxp2)\n",
    "        conv3 = Conv3D(96, (3, 3, 3), strides=(1, 1, 1), kernel_initializer='he_normal', name='conv3')(zero3)\n",
    "        batc3 = BatchNormalization(name='batc3')(conv3)\n",
    "        actv3 = Activation('relu', name='actv3')(batc3)\n",
    "        drop3 = SpatialDropout3D(0.5)(actv3)\n",
    "        maxp3 = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max3')(drop3)\n",
    "\n",
    "        resh1 = TimeDistributed(Flatten())(maxp3)\n",
    "\n",
    "        gru_1 = Bidirectional(GRU(256, return_sequences=True, kernel_initializer='Orthogonal', name='gru1'), merge_mode='concat')(resh1)\n",
    "        gru_2 = Bidirectional(GRU(256, return_sequences=True , kernel_initializer='Orthogonal', name='gru2'), merge_mode='concat')(gru_1)\n",
    "\n",
    "        # transforms RNN output to character activations:\n",
    "        dense1 = Dense(output_size, kernel_initializer='he_normal', name='dense1')(gru_2)\n",
    "\n",
    "        y_pred = Activation('softmax', name='softmax')(dense1)\n",
    "        print(\"self.y_pred: \",y_pred)\n",
    "\n",
    "        labels = Input(name='the_labels', shape=[absolute_max_string_len], dtype='float32')\n",
    "        print(\"self.y_pred: \",labels)\n",
    "        input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "        label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "        loss_out = CTC('ctc', [y_pred, labels, input_length, label_length])\n",
    "\n",
    "        model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "        return model\n",
    "\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VLa9z7WppXFb",
    "outputId": "4721cb0f-5e6e-44e5-9072-40d98baa5b22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/keras/layers/normalization/batch_normalization.py:581: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "self.y_pred:  Tensor(\"softmax/Softmax:0\", shape=(None, 75, 43), dtype=float32)\n",
      "self.y_pred:  Tensor(\"the_labels:0\", shape=(None, 29), dtype=float32)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " the_input (InputLayer)         [(None, 75, 100, 50  0           []                               \n",
      "                                , 3)]                                                             \n",
      "                                                                                                  \n",
      " zero1 (ZeroPadding3D)          (None, 77, 104, 54,  0           ['the_input[0][0]']              \n",
      "                                 3)                                                               \n",
      "                                                                                                  \n",
      " conv1 (Conv3D)                 (None, 75, 50, 25,   7232        ['zero1[0][0]']                  \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batc1 (BatchNormalization)     (None, 75, 50, 25,   128         ['conv1[0][0]']                  \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " actv1 (Activation)             (None, 75, 50, 25,   0           ['batc1[0][0]']                  \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " spatial_dropout3d (SpatialDrop  (None, 75, 50, 25,   0          ['actv1[0][0]']                  \n",
      " out3D)                         32)                                                               \n",
      "                                                                                                  \n",
      " max1 (MaxPooling3D)            (None, 75, 25, 12,   0           ['spatial_dropout3d[0][0]']      \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " zero2 (ZeroPadding3D)          (None, 77, 29, 16,   0           ['max1[0][0]']                   \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv2 (Conv3D)                 (None, 75, 25, 12,   153664      ['zero2[0][0]']                  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batc2 (BatchNormalization)     (None, 75, 25, 12,   256         ['conv2[0][0]']                  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " actv2 (Activation)             (None, 75, 25, 12,   0           ['batc2[0][0]']                  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " spatial_dropout3d_1 (SpatialDr  (None, 75, 25, 12,   0          ['actv2[0][0]']                  \n",
      " opout3D)                       64)                                                               \n",
      "                                                                                                  \n",
      " max2 (MaxPooling3D)            (None, 75, 12, 6, 6  0           ['spatial_dropout3d_1[0][0]']    \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " zero3 (ZeroPadding3D)          (None, 77, 14, 8, 6  0           ['max2[0][0]']                   \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3 (Conv3D)                 (None, 75, 12, 6, 9  165984      ['zero3[0][0]']                  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batc3 (BatchNormalization)     (None, 75, 12, 6, 9  384         ['conv3[0][0]']                  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " actv3 (Activation)             (None, 75, 12, 6, 9  0           ['batc3[0][0]']                  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " spatial_dropout3d_2 (SpatialDr  (None, 75, 12, 6, 9  0          ['actv3[0][0]']                  \n",
      " opout3D)                       6)                                                                \n",
      "                                                                                                  \n",
      " max3 (MaxPooling3D)            (None, 75, 6, 3, 96  0           ['spatial_dropout3d_2[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 75, 1728)    0           ['max3[0][0]']                   \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 75, 512)      3050496     ['time_distributed[0][0]']       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 14:41:43.862184: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Fill/ctc/stack_1' with dtype int32 and shape [1]\n",
      "\t [[{{node Fill/ctc/stack_1}}]]\n",
      "2023-05-01 14:41:43.862302: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Fill/ctc/stack_1' with dtype int32 and shape [1]\n",
      "\t [[{{node Fill/ctc/stack_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 75, 512)     1182720     ['bidirectional[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 75, 43)       22059       ['bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " softmax (Activation)           (None, 75, 43)       0           ['dense1[0][0]']                 \n",
      "                                                                                                  \n",
      " the_labels (InputLayer)        [(None, 29)]         0           []                               \n",
      "                                                                                                  \n",
      " input_length (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " label_length (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " ctc (Lambda)                   (None, 1)            0           ['softmax[0][0]',                \n",
      "                                                                  'the_labels[0][0]',             \n",
      "                                                                  'input_length[0][0]',           \n",
      "                                                                  'label_length[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,582,923\n",
      "Trainable params: 4,582,539\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution() \n",
    "tf.compat.v1.experimental.output_all_intermediates(True)\n",
    "from matplotlib import pyplot\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "model = build()\n",
    "print(model.summary())\n",
    "# plot graph\n",
    "\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "# checkpoint_path = \"drive/MyDrive/datasets/training/cp-{epoch:04d}.ckpt\"\n",
    "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#    checkpoint_path, verbose=1, save_weights_only=True,\n",
    "#    # Save weights, every epoch.\n",
    "#    save_freq='epoch')\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='loss', mode='min', verbose=1,patience=5)\n",
    "mc = ModelCheckpoint('/tf/best_model.h5', monitor='loss', mode='min', verbose=1, save_best_only=True)\n",
    "    # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=adam,metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "# print(latest)\n",
    "#model.load_weights(latest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkJDPtHWWcsT"
   },
   "source": [
    "# **Model Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mekJ6f212EOo",
    "outputId": "80a6b032-1c58-4f7f-e889-74518683d8f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "WARNING:tensorflow:Layer gru1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/keras/layers/normalization/batch_normalization.py:562: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "tf.compat.v1.disable_eager_execution() \n",
    "tf.compat.v1.experimental.output_all_intermediates(True)\n",
    "from matplotlib import pyplot\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "# checkpoint_path = \"drive/MyDrive/datasets/training/cp-{epoch:04d}.ckpt\"\n",
    "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#    checkpoint_path, verbose=1, save_weights_only=True,\n",
    "#    # Save weights, every epoch.\n",
    "#    save_freq='epoch')\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='loss', mode='min', verbose=1,patience=10)\n",
    "mc = ModelCheckpoint('drive/MyDrive/lipnetWthSil/best_model.h5', monitor='loss', mode='min', verbose=1, save_best_only=True)\n",
    "    # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "\n",
    "model= keras.models.load_model('drive/MyDrive/lipnetWthSil/best_model.h5',compile=False)\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=adam,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0f5ZowDAWhhQ"
   },
   "source": [
    "# **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YziyJGjscUoN",
    "outputId": "403a4c19-8d55-4bd6-e1fb-41d563baee5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 14:41:49.983799: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
      "2023-05-01 14:41:50.200190: W tensorflow/c/c_api.cc:300] Operation '{name:'training/Adam/conv1/kernel/v/Assign' id:2546 op device:{requested: '', assigned: ''} def:{{{node training/Adam/conv1/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/conv1/kernel/v, training/Adam/conv1/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 14:41:52.103221: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 13500000 exceeds 10% of free system memory.\n",
      "2023-05-01 14:41:52.111442: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 15567552 exceeds 10% of free system memory.\n",
      "2023-05-01 14:41:52.118665: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 36000000 exceeds 10% of free system memory.\n",
      "2023-05-01 14:41:52.218386: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 36000000 exceeds 10% of free system memory.\n",
      "2023-05-01 14:41:52.241264: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 36000000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "his=model.fit(\n",
    "    x=new_data[0],\n",
    "    y=new_data[1],\n",
    "    batch_size=32,\n",
    "    epochs=1000,\n",
    "    initial_epoch=143,\n",
    "    max_queue_size=10,\n",
    "    workers=8,\n",
    "    use_multiprocessing=False,callbacks = [es,mc]\n",
    ")\n",
    "pyplot.plot(his.history['loss'], label='train')\n",
    "\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDasS8EYWrdD"
   },
   "source": [
    "# **Load Model For Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uUISltfGTeXF"
   },
   "outputs": [],
   "source": [
    "model= keras.models.load_model('drive/MyDrive/lipnetWthSil/best_model.h5',compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8oe5l6S21Xf"
   },
   "source": [
    "# **Unknown Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SHRB719Dxr7h",
    "outputId": "863338c1-f384-4ff6-a696-41a05ceb2dab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data from disk...\n",
      "46\n",
      "newframes:  (50, 100, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e5888ec90060>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0minput_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0my_pred\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0mprediction_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mresult\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m         return func.predict(\n\u001b[0m\u001b[1;32m   1059\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"steps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m         )\n\u001b[0;32m--> 801\u001b[0;31m         return predict_loop(\n\u001b[0m\u001b[1;32m    802\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;31m# function we recompile the metrics based on the updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# sample_weight_mode value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_execution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;31m# Prepare validation data. Hold references to the iterator and the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36m_make_execution_function\u001b[0;34m(model, mode)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         )\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_execution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_make_execution_function\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   2367\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2369\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2370\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_make_predict_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2351\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_function_kwargs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2352\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2353\u001b[0;31m                 self.predict_function = backend.function(\n\u001b[0m\u001b[1;32m   2354\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2355\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, name, **kwargs)\u001b[0m\n\u001b[1;32m   4645\u001b[0m                 ) % key\n\u001b[1;32m   4646\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4647\u001b[0;31m     return GraphExecutionFunction(\n\u001b[0m\u001b[1;32m   4648\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4649\u001b[0m     )\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, updates, name, **session_kwargs)\u001b[0m\n\u001b[1;32m   4417\u001b[0m         \u001b[0;31m# dependencies in call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4418\u001b[0m         \u001b[0;31m# Index 0 = total loss or model output for `predict`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4419\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4420\u001b[0m             \u001b[0mupdates_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4421\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcontrol_dependencies\u001b[0;34m(control_inputs)\u001b[0m\n\u001b[1;32m   5637\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mNullContextmanager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5638\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5639\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrol_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcontrol_dependencies\u001b[0;34m(self, control_inputs)\u001b[0m\n\u001b[1;32m   5091\u001b[0m           (hasattr(c, \"_handle\") and hasattr(c, \"op\"))):\n\u001b[1;32m   5092\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5093\u001b[0;31m       \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5094\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5095\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3997\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3998\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4000\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   4084\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4085\u001b[0m       \u001b[0;31m# We give up!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4086\u001b[0;31m       raise TypeError(\"Can not convert a %s into a %s.\" %\n\u001b[0m\u001b[1;32m   4087\u001b[0m                       (type(obj).__name__, types_str))\n\u001b[1;32m   4088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can not convert a KerasTensor into a Tensor or Operation."
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from jiwer import wer\n",
    "from jiwer import cer\n",
    "avg_error=0\n",
    "cer_error=0\n",
    "prediction_model = keras.models.Model(\n",
    "    model.get_layer(name=\"the_input\").input, model.get_layer(name=\"softmax\").output\n",
    ")\n",
    "\n",
    "CURRENT_PATH = os.path.dirname('drive/MyDrive/lipnetWthSil/')\n",
    "PREDICT_GREEDY      = False\n",
    "PREDICT_BEAM_WIDTH  = 200\n",
    "PREDICT_DICTIONARY  = os.path.join(CURRENT_PATH,'dictionaries','urdu_sentences.txt')\n",
    "absolute_max_string_len=26\n",
    "output_size=41\n",
    "print (\"\\nLoading data from disk...\")\n",
    "count_vids=0\n",
    "path=\"/content/drive/MyDrive/lipnetWthSil/8_train/*/*\"\n",
    "for vid_path in glob.glob(path):\n",
    "  splitpaths=vid_path.split(\"/\")\n",
    "  \n",
    "  vid_name=splitpaths[7].split('.')\n",
    "\n",
    "  if(len(vid_name)>1 and vid_name[1]=='mp4'):\n",
    "    \n",
    "    video=Video().from_frames(vid_path)\n",
    "    spell = Spell(path=PREDICT_DICTIONARY)\n",
    "    decoder = Decoder(greedy=PREDICT_GREEDY, beam_width=PREDICT_BEAM_WIDTH,\n",
    "                          postprocessors=[labels_to_text, spell.sentence])\n",
    "\n",
    "    X_data       = np.array([video.data]).astype(np.float32) /255\n",
    "    input_length = np.array([len(video.data)])\n",
    "  \n",
    "    y_pred         = prediction_model.predict(X_data)\n",
    "    print(y_pred.shape)\n",
    "    result         = decoder.decode(y_pred, input_length)\n",
    "   \n",
    "    align_path=\"\"\n",
    "    for i in range(7):\n",
    "        align_path+=splitpaths[i]+'/'\n",
    "    print(\"align_path\",align_path)\n",
    "    align_path+=\"*\"\n",
    "    referen=\"\"\n",
    "    for al_path in glob.glob(align_path):\n",
    "       splitpaths=al_path.split(\"/\")\n",
    "       align_name=splitpaths[7].split('.')\n",
    "       print(align_name)\n",
    "       if(len(align_name)>1 and align_name[1]=='align'):\n",
    "         with open(al_path, 'r',encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "         list_of_strings=[]\n",
    "         for i in range(len(lines)):\n",
    "\n",
    "              lines[i]=lines[i].strip()\n",
    "              # print(\"linesss: \",lines[i])\n",
    "              new_array = lines[i].split(' ')\n",
    "                # print(\"new_array: \", new_array)\n",
    "                # print(\"new_array[0]: \", new_array[0])\n",
    "              if(new_array[0]!=''):\n",
    "                list_of_strings.append(new_array[0])\n",
    "         align=list_of_strings\n",
    "         #print(align[1:7])\n",
    "         #self.align=align[1:7]\n",
    "         print(\"align: \",align[1:7])\n",
    "         stringref=align[1:7]\n",
    "        \n",
    "         for i in range(len(stringref)):\n",
    "           if(i<len(stringref)-1):\n",
    "            referen+=stringref[i]+\" \"\n",
    "           else:\n",
    "            referen+=stringref[i]\n",
    "    print(\"Reference: \",referen)\n",
    "    print(\"Result: \",result)\n",
    "    error = wer(referen, result)\n",
    "    err = cer(referen, result)\n",
    "    print(\"wer error: \",error)\n",
    "    print(\"cer error: \",err)\n",
    "    avg_error+=error\n",
    "    cer_error+=err\n",
    "    count_vids+=1\n",
    "\n",
    "print(\"Average word error rate: \",avg_error/count_vids)\n",
    "print(\"Average character error rate: \",cer_error/count_vids)\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQUxMwAl3HvA"
   },
   "source": [
    "# **Evaluate On Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TB1tnCRIswkV",
    "outputId": "39a24bb8-b9ee-46a5-b41d-c8f2684774db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data from disk...\n",
      "60\n",
      "newframes:  (50, 100, 3)\n",
      "(1, 75, 41)\n",
      "decode:  ([<tf.Tensor 'SparseToDense:0' shape=(1, 75) dtype=int64>], <tf.Tensor 'CTCBeamSearchDecoder:3' shape=(1, 1) dtype=float32>)\n",
      "align_path /content/drive/MyDrive/lipnetWthSil/7_train/7/wo_konsa_hoon_han_kon_nau/\n",
      "['103', 'avi']\n",
      "['align']\n",
      "['_audio', 'wav']\n",
      "['103', 'align']\n",
      "align:  ['وہ', 'کونسا', 'ہوں', 'ہاں', 'کون', 'نو']\n",
      "['102', 'txt']\n",
      "['__temp__', 'mp4']\n",
      "Reference:  وہ کونسا ہوں ہاں کون نو\n",
      "Result:  ['ک ی ک ک']\n",
      "wer error:  23\n",
      "cer error:  0.782608695652174\n",
      "55\n",
      "newframes:  (50, 100, 3)\n",
      "(1, 75, 41)\n",
      "decode:  ([<tf.Tensor 'SparseToDense_1:0' shape=(1, 75) dtype=int64>], <tf.Tensor 'CTCBeamSearchDecoder_1:3' shape=(1, 1) dtype=float32>)\n",
      "align_path /content/drive/MyDrive/lipnetWthSil/7_train/7/wo_konsa_hoon_han_kyun_do/\n",
      "['_audio', 'wav']\n",
      "['align']\n",
      "['104', 'avi']\n",
      "['104', 'align']\n",
      "align:  ['وہ', 'کونسا', 'ہوں', 'ہاں', 'کیوں', 'دو']\n",
      "['103', 'txt']\n",
      "['__temp__', 'mp4']\n",
      "Reference:  وہ کونسا ہوں ہاں کیوں دو\n",
      "Result:  ['ک ی ک ک']\n",
      "wer error:  24\n",
      "cer error:  0.7916666666666666\n",
      "55\n",
      "newframes:  (50, 100, 3)\n",
      "(1, 75, 41)\n",
      "decode:  ([<tf.Tensor 'SparseToDense_2:0' shape=(1, 75) dtype=int64>], <tf.Tensor 'CTCBeamSearchDecoder_2:3' shape=(1, 1) dtype=float32>)\n",
      "align_path /content/drive/MyDrive/lipnetWthSil/7_train/7/wo_kitne_thay_jee_kon_ek/\n",
      "['align']\n",
      "['_audio', 'wav']\n",
      "['99', 'avi']\n",
      "['99', 'align']\n",
      "align:  ['وہ', 'کتنے', 'تھے', 'جی', 'کون', 'ایک']\n",
      "['98', 'txt']\n",
      "['__temp__', 'mp4']\n",
      "Reference:  وہ کتنے تھے جی کون ایک\n",
      "Result:  ['ک ی ک ک']\n",
      "wer error:  22\n",
      "cer error:  0.6818181818181818\n",
      "54\n",
      "newframes:  (50, 100, 3)\n",
      "(1, 75, 41)\n",
      "decode:  ([<tf.Tensor 'SparseToDense_3:0' shape=(1, 75) dtype=int64>], <tf.Tensor 'CTCBeamSearchDecoder_3:3' shape=(1, 1) dtype=float32>)\n",
      "align_path /content/drive/MyDrive/lipnetWthSil/7_train/7/wo_konsa_thay_nai_kyun_nau/\n",
      "['_audio', 'wav']\n",
      "['align']\n",
      "['107', 'avi']\n",
      "['107', 'align']\n",
      "align:  ['وہ', 'کونسا', 'تھے', 'نہیں', 'کیوں', 'نو']\n",
      "['106', 'txt']\n",
      "['__temp__', 'mp4']\n",
      "Reference:  وہ کونسا تھے نہیں کیوں نو\n",
      "Result:  ['ک ک ک ک']\n",
      "wer error:  25\n",
      "cer error:  0.8\n",
      "67\n",
      "newframes:  (50, 100, 3)\n",
      "(1, 75, 41)\n",
      "decode:  ([<tf.Tensor 'SparseToDense_4:0' shape=(1, 75) dtype=int64>], <tf.Tensor 'CTCBeamSearchDecoder_4:3' shape=(1, 1) dtype=float32>)\n",
      "align_path /content/drive/MyDrive/lipnetWthSil/7_train/7/wo_konsa_tha_han_kab_paanch/\n",
      "['_audio', 'wav']\n",
      "['align']\n",
      "['108', 'avi']\n",
      "['108', 'align']\n",
      "align:  ['وہ', 'کونسا', 'تھا', 'ہاں', 'کب', 'پانچھ']\n",
      "['107', 'txt']\n",
      "['__temp__', 'mp4']\n",
      "Reference:  وہ کونسا تھا ہاں کب پانچھ\n",
      "Result:  ['ک ی ک ک']\n",
      "wer error:  25\n",
      "cer error:  0.8\n",
      "56\n",
      "newframes:  (50, 100, 3)\n",
      "(1, 75, 41)\n",
      "decode:  ([<tf.Tensor 'SparseToDense_5:0' shape=(1, 75) dtype=int64>], <tf.Tensor 'CTCBeamSearchDecoder_5:3' shape=(1, 1) dtype=float32>)\n",
      "align_path /content/drive/MyDrive/lipnetWthSil/7_train/7/wo_kitne_thay_nai_kon_chaar/\n",
      "['100', 'avi']\n",
      "['align']\n",
      "['_audio', 'wav']\n",
      "['100', 'align']\n",
      "align:  ['وہ', 'کتنے', 'تھے', 'نہیں', 'کون', 'چار']\n",
      "['99', 'txt']\n",
      "['__temp__', 'mp4']\n",
      "Reference:  وہ کتنے تھے نہیں کون چار\n",
      "Result:  ['ک ی ک ک']\n",
      "wer error:  24\n",
      "cer error:  0.75\n",
      "55\n",
      "newframes:  (50, 100, 3)\n",
      "(1, 75, 41)\n",
      "decode:  ([<tf.Tensor 'SparseToDense_6:0' shape=(1, 75) dtype=int64>], <tf.Tensor 'CTCBeamSearchDecoder_6:3' shape=(1, 1) dtype=float32>)\n",
      "align_path /content/drive/MyDrive/lipnetWthSil/7_train/7/wo_konsa_thay_jee_kon_nau/\n",
      "['106', 'avi']\n",
      "['_audio', 'wav']\n",
      "['align']\n",
      "['106', 'align']\n",
      "align:  ['وہ', 'کونسا', 'تھے', 'جی', 'کون', 'نو']\n",
      "['105', 'txt']\n",
      "['__temp__', 'mp4']\n",
      "Reference:  وہ کونسا تھے جی کون نو\n",
      "Result:  ['ک ی ک ک']\n",
      "wer error:  22\n",
      "cer error:  0.7272727272727273\n",
      "53\n",
      "newframes:  (50, 100, 3)\n",
      "(1, 75, 41)\n",
      "decode:  ([<tf.Tensor 'SparseToDense_7:0' shape=(1, 75) dtype=int64>], <tf.Tensor 'CTCBeamSearchDecoder_7:3' shape=(1, 1) dtype=float32>)\n",
      "align_path /content/drive/MyDrive/lipnetWthSil/7_train/7/wo_kitne_tha_nai_kyun_paanch/\n",
      "['_audio', 'wav']\n",
      "['align']\n",
      "['101', 'avi']\n",
      "['101', 'align']\n",
      "align:  ['وہ', 'کتنے', 'تھا', 'نہیں', 'کیوں', 'پانچھ']\n",
      "['100', 'txt']\n",
      "['__temp__', 'mp4']\n",
      "Reference:  وہ کتنے تھا نہیں کیوں پانچھ\n",
      "Result:  ['ک ی ک ک']\n",
      "wer error:  27\n",
      "cer error:  0.7777777777777778\n",
      "57\n",
      "newframes:  (50, 100, 3)\n",
      "(1, 75, 41)\n",
      "decode:  ([<tf.Tensor 'SparseToDense_8:0' shape=(1, 75) dtype=int64>], <tf.Tensor 'CTCBeamSearchDecoder_8:3' shape=(1, 1) dtype=float32>)\n",
      "align_path /content/drive/MyDrive/lipnetWthSil/7_train/7/wo_kitne_thay_jee_kon_chaar/\n",
      "['_audio', 'wav']\n",
      "['align']\n",
      "['98', 'avi']\n",
      "['98', 'align']\n",
      "align:  ['وہ', 'کتنے', 'تھے', 'جی', 'کون', 'چار']\n",
      "['97', 'txt']\n",
      "['__temp__', 'mp4']\n",
      "Reference:  وہ کتنے تھے جی کون چار\n",
      "Result:  ['ک ی ک ک']\n",
      "wer error:  22\n",
      "cer error:  0.7272727272727273\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2c6c0fd0b1c9>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvid_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mvideo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVideo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mspell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPREDICT_DICTIONARY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     decoder = Decoder(greedy=PREDICT_GREEDY, beam_width=PREDICT_BEAM_WIDTH,\n",
      "\u001b[0;32m<ipython-input-16-8dd8ca2433ed>\u001b[0m in \u001b[0;36mfrom_frames\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_video_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0;31m# frames_path = sorted([os.path.join(path, x) for x in os.listdir(path)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# frames = [ndimage.imread(frame_path) for frame_path in frames_path]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-8dd8ca2433ed>\u001b[0m in \u001b[0;36mget_video_frames\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mvideogen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvideogen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;31m#print(\"frames: \",frames)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-8dd8ca2433ed>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mvideogen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvideogen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;31m#print(\"frames: \",frames)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/skvideo/io/io.py\u001b[0m in \u001b[0;36mvreader\u001b[0;34m(fname, height, width, num_frames, as_grey, inputdict, outputdict, backend, verbosity)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFFmpegReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputdict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputdict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnextFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mas_grey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mvshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/skvideo/io/ffmpeg.py\u001b[0m in \u001b[0;36mnextFrame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \"\"\"\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputframenum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/skvideo/io/ffmpeg.py\u001b[0m in \u001b[0;36m_readFrame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;31m# Read and convert to numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;31m# t0 = time.time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_frame_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/skvideo/io/ffmpeg.py\u001b[0m in \u001b[0;36m_read_frame_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;31m# Read framesize bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframesize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mframesize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from jiwer import cer\n",
    "cer_error=0\n",
    "avg_error=0\n",
    "prediction_model = keras.models.Model(\n",
    "    model.get_layer(name=\"the_input\").input, model.get_layer(name=\"softmax\").output\n",
    ")\n",
    "\n",
    "CURRENT_PATH = os.path.dirname('drive/MyDrive/lipnetWthSil/')\n",
    "PREDICT_GREEDY      = False\n",
    "PREDICT_BEAM_WIDTH  = 200\n",
    "PREDICT_DICTIONARY  = os.path.join(CURRENT_PATH,'dictionaries','urdu_sentences.txt')\n",
    "absolute_max_string_len=26\n",
    "output_size=41\n",
    "print (\"\\nLoading data from disk...\")\n",
    "count_vids=0\n",
    "path=\"/content/drive/MyDrive/lipnetWthSil/7_train/7/*/*\"\n",
    "for vid_path in glob.glob(path):\n",
    "  splitpaths=vid_path.split(\"/\")\n",
    "  \n",
    "  vid_name=splitpaths[8].split('.')\n",
    "\n",
    "  if(len(vid_name)>1 and vid_name[1]=='mp4'):\n",
    "    \n",
    "    video=Video().from_frames(vid_path)\n",
    "    spell = Spell(path=PREDICT_DICTIONARY)\n",
    "    decoder = Decoder(greedy=PREDICT_GREEDY, beam_width=PREDICT_BEAM_WIDTH,\n",
    "                          postprocessors=[labels_to_text, spell.sentence])\n",
    "\n",
    "    X_data       = np.array([video.data]).astype(np.float32) /255\n",
    "    input_length = np.array([len(video.data)])\n",
    "  \n",
    "    y_pred         = prediction_model.predict(X_data)\n",
    "    print(y_pred.shape)\n",
    "    result         = decoder.decode(y_pred, input_length)\n",
    "   \n",
    "    align_path=\"\"\n",
    "    for i in range(8):\n",
    "        align_path+=splitpaths[i]+'/'\n",
    "    print(\"align_path\",align_path)\n",
    "    align_path+=\"*\"\n",
    "    referen=\"\"\n",
    "    for al_path in glob.glob(align_path):\n",
    "       splitpaths=al_path.split(\"/\")\n",
    "       align_name=splitpaths[8].split('.')\n",
    "       print(align_name)\n",
    "       if(len(align_name)>1 and align_name[1]=='align'):\n",
    "         with open(al_path, 'r',encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "         list_of_strings=[]\n",
    "         for i in range(len(lines)):\n",
    "\n",
    "              lines[i]=lines[i].strip()\n",
    "              # print(\"linesss: \",lines[i])\n",
    "              new_array = lines[i].split(' ')\n",
    "                # print(\"new_array: \", new_array)\n",
    "                # print(\"new_array[0]: \", new_array[0])\n",
    "              if(new_array[0]!=''):\n",
    "                list_of_strings.append(new_array[0])\n",
    "         align=list_of_strings\n",
    "         #print(align[1:7])\n",
    "         #self.align=align[1:7]\n",
    "         print(\"align: \",align[1:7])\n",
    "         stringref=align[1:7]\n",
    "        \n",
    "         for i in range(len(stringref)):\n",
    "           if(i<len(stringref)-1):\n",
    "            referen+=stringref[i]+\" \"\n",
    "           else:\n",
    "            referen+=stringref[i]\n",
    "    print(\"Reference: \",referen)\n",
    "    print(\"Result: \",result)\n",
    "    error = wer(referen, result)\n",
    "    err = cer(referen, result)\n",
    "    print(\"wer error: \",error)\n",
    "    print(\"cer error: \",err)\n",
    "    avg_error+=error\n",
    "    cer_error+=err\n",
    "    count_vids+=1\n",
    "\n",
    "print(\"Average word error rate: \",avg_error/count_vids)\n",
    "print(\"Average character error rate: \",cer_error/count_vids)\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UnKIpymOIqxK",
    "outputId": "6b13f6ad-8a64-4ee3-9107-8e7f6f6153f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word error rate:  39.10256410256411\n",
      "Average character error rate:  12.254496772891423\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Average word error rate: \",(avg_error/count_vids)*100)\n",
    "print(\"Average character error rate: \",(cer_error/count_vids)*100)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "jHRUF0MOV2N2",
    "sIYtWuhoV-6b",
    "XDbyKkVNWD4e",
    "QF9HtJOXWUDT",
    "qkJDPtHWWcsT",
    "0f5ZowDAWhhQ",
    "rDasS8EYWrdD",
    "u8oe5l6S21Xf",
    "GQUxMwAl3HvA"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
